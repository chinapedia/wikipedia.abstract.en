DNC_training_recall_task.gif and a 1 bit interrupt signal. Upper right: the model's output.]]

A DIFFERENTIABLE NEURAL COMPUTER (DNC) is a memory augmented neural network architecture (MANN), which is typically (not by definition) recurrent in its implementation. The model was published in 2016 by Alex Graves et al. of DeepMind.[1]


Applications

As DNC indirectly takes inspiration from Von-Neumann architecture, DNCs are likely to excel and outperform conventional architectures in tasks that are fundamentally algorithmic and can't be learned just by finding a complex decision boundary.

So far, DNCs have only been demonstrated to handle relatively simple tasks, which could have been easily solved using conventional computer programming decades ago. But DNCs don't need to be programmed for each problem they are applied to, but can instead be trained. This attention span allows the user to feed complex data structures such as graphs sequentially, and recall them during later use. Furthermore, they can learn some aspects of symbolic reasoning and apply it to the use of working memory. The researches who published the method see promise that DNCs can be trained to perform complex, structured tasks[2][3] and address big-data applications that require some sort of rational reasoning, such as generating video commentaries or semantic text analysis.[4][5]

DNC can be trained to navigate a variety of rapid transit systems, and then what the DNC learns can be applied, for example, to get around on the London Underground. A neural network without memory would typically have to learn about each different transit system from scratch. On graph traversal and sequence-processing tasks with supervised learning, DNCs performed better than alternatives such as long short-term memory or a neural turing machine.[6] With a reinforcement learning approach to a block puzzle problem inspired by SHRDLU, DNC was trained via curriculum learning, and learned to make a plan. It performed better than a traditional recurrent neural network.[7]


Architecture

Differentiable_Neural_Computer.png

DNC networks were introduced as an extension of the Neural Turing Machine (NTM), with the addition of memory attention mechanisms that control where the memory is stored, and temporal attention that records the order of events. This structure allows DNCs to be more robust and abstract than a NTM, and still perform tasks that have longer-term dependencies than some of its predecessors such as the LSTM network. The memory, which is simply a matrix, can be allocated dynamically and accessed indefinitely. The DNC is differentiable end-to-end (each subcomponent of the model is differentiable, therefore so is the whole model). This makes it possible to optimize them efficiently using gradient descent. It learns how to store and retrieve the information such that it satisfies the task execution.[8][9][10]

The DNC model is similar to the Von Neumann architecture, and because of the resizability of memory, it is Turing complete.[11] Differentiable Neural Computers were inspired by the mammalian hippocampus.[12]

Traditional DNC

DNC, as originally published[13]

+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| INDEPENDENT VARIABLES                                                                                                                                                                                                                                                           |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| X_(t)                                                                                                                                                                                                                                                                           | Input vector                               |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| Z_(t)                                                                                                                                                                                                                                                                           | Target vector                              |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| CONTROLLER                                                                                                                                                                                                                                                                      |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| Χ_(t) = [X_(t); R_(t − 1)¹; ⋯; R_(t − 1)^(R)]                                                                                                                                                                                                                                   | Controller input matrix                    |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
|                                                                                                                                                                                                                                                                                 |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| Deep (layered) LSTM                                                                                                                                                                                                                                                             | ∀ 0 ≤ l ≤ L                                |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| I_(t)^(l) = σ(W_(i)^(l)[Χ_(t); H_(t − 1)^(l); H_(t)^(l − 1)] + B_(i)^(l))                                                                                                                                                                                                       | Input gate vector                          |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| O_(t)^(l) = σ(W_(o)^(l)[Χ_(t); H_(t − 1)^(l); H_(t)^(l − 1)] + B_(o)^(l))                                                                                                                                                                                                       | Output gate vector                         |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| F_(t)^(l) = σ(W_(f)^(l)[Χ_(t); H_(t − 1)^(l); H_(t)^(l − 1)] + B_(f)^(l))                                                                                                                                                                                                       | Forget gate vector                         |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| S_(t)^(l) = F_(t)^(l)S_(t − 1)^(l) + I_(t)^(l)tanh (W_(s)^(l)[Χ_(t); H_(t − 1)^(l); H_(t)^(l − 1)] + B_(s)^(l))                                                                                                                                                                 | State gate vector,                         |
|                                                                                                                                                                                                                                                                                 | s₀ = 0                                     |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| H_(t)^(l) = O_(t)^(l)tanh (S_(t)^(l))                                                                                                                                                                                                                                           | Hidden gate vector,                        |
|                                                                                                                                                                                                                                                                                 | h₀ = 0; h_(t)⁰ = 0 ∀ t                     |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
|                                                                                                                                                                                                                                                                                 |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| Y_(t) = W_(y)[H_(t)¹; ⋯; H_(t)^(L)] + W_(r)[R_(t)¹; ⋯; R_(t)^(R)]                                                                                                                                                                                                               | DNC output vector                          |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| READ & WRITE HEADS                                                                                                                                                                                                                                                              |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| ξ_(t) = W_(ξ)[h_(t)¹; ⋯; h_(t)^(L)]                                                                                                                                                                                                                                             | Interface parameters                       |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| $=[\mathbf{k}_t^{r,1};\cdots;\mathbf{k}_t^{r,R};\hat{\beta}_t^{r,1};\cdots;\hat{\beta}_t^{r,R};\mathbf{k}_t^w;\hat{\beta_t^w};\mathbf{\hat{e}}_t;\mathbf{v}_t;\hat{f_t^1};\cdots;\hat{f_t^R};\hat{g}_t^a;\hat{g}_t^w;\hat{\boldsymbol\pi}_t^1;\cdots;\hat{\boldsymbol\pi}_t^R]$ |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
|                                                                                                                                                                                                                                                                                 |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| Read heads                                                                                                                                                                                                                                                                      | ∀ 1 ≤ i ≤ R                                |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| K_(t)^(r, i)                                                                                                                                                                                                                                                                    | Read keys                                  |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| β_(t)^(r, i) = oneplus(β̂_(t)^(r, i))                                                                                                                                                                                                                                            | Read strengths                             |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| f_(t)^(i) = σ(f̂_(t)^(i))                                                                                                                                                                                                                                                        | Free gates                                 |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| $\boldsymbol\pi_t^i=\text{softmax}(\hat{\boldsymbol\pi}_t^i)$                                                                                                                                                                                                                   | Read modes,                                |
|                                                                                                                                                                                                                                                                                 | Π_(t)^(i) ∈ ℝ³                             |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
|                                                                                                                                                                                                                                                                                 |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| Write head                                                                                                                                                                                                                                                                      |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| K_(t)^(w)                                                                                                                                                                                                                                                                       | Write key                                  |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| β_(t)^(w) = β̂_(t)^(w)                                                                                                                                                                                                                                                           | Write strength                             |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| E_(t) = σ(Ê_(t))                                                                                                                                                                                                                                                                | Erase vector                               |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| V_(t)                                                                                                                                                                                                                                                                           | Write vector                               |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| g_(t)^(a) = σ(ĝ_(t)^(a))                                                                                                                                                                                                                                                        | Allocation gate                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| g_(t)^(w) = σ(ĝ_(t)^(w))                                                                                                                                                                                                                                                        | Write gate                                 |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| MEMORY                                                                                                                                                                                                                                                                          |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| M_(t) = M_(t − 1) ∘ (E − W_(t)^(w)E_(t)^(⊺)) + W_(t)^(w)V_(t)^(⊺)                                                                                                                                                                                                               | Memory matrix,                             |
|                                                                                                                                                                                                                                                                                 | Matrix of ones E ∈ ℝ^(N × W)               |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| U_(t) = (U_(t − 1) + W_(t − 1)^(w) − U_(t − 1) ∘ W_(t − 1)^(w)) ∘ Ψ_(t)                                                                                                                                                                                                         | Usage vector                               |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| P_(t) = (1−∑_(i)W_(t)^(w)[i])P_(t − 1) + W_(t)^(w)                                                                                                                                                                                                                              | Precedence weighting,                      |
|                                                                                                                                                                                                                                                                                 | P₀ = 0                                     |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| L_(t) = (1 − I)[(1−W_(t)^(w)[i]−W_(t)^(j))L_(t − 1)[i,j]+W_(t)^(w)[i]P_(t − 1)^(j)]                                                                                                                                                                                             | Temporal link matrix,                      |
|                                                                                                                                                                                                                                                                                 | L₀ = 0                                     |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| W_(t)^(w) = g_(t)^(w)[g_(t)^(a)A_(t) + (1 − g_(t)^(a))C_(t)^(w)]                                                                                                                                                                                                                | Write weighting                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| W_(t)^(r, i) = Π_(t)^(i)[1]B_(t)^(i) + Π_(t)^(i)[2]c_(t)^(r, i) + Π_(t)^(i)[3]f_(t)^(i)                                                                                                                                                                                         | Read weighting                             |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| R_(t)^(i) = M_(t)^(⊺)W_(t)^(r, i)                                                                                                                                                                                                                                               | Read vectors                               |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
|                                                                                                                                                                                                                                                                                 |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| $\mathcal{C}(M,\mathbf{k},\beta)[i]=\frac{\exp\{\mathcal{D}(\mathbf{k},M[i,\cdot])\beta\}}{\sum_j\exp\{\mathcal{D}(\mathbf{k},M[j,\cdot])\beta\}}$                                                                                                                              | Content-based addressing,                  |
|                                                                                                                                                                                                                                                                                 | Lookup key K, key strength β               |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| ϕ_(t)                                                                                                                                                                                                                                                                           | Indices of U_(t),                          |
|                                                                                                                                                                                                                                                                                 | sorted in ascending order of usage         |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| $\mathbf{a}_t[\phi_t[j]]=(1-\mathbf{u}_t[\phi_t[j]])\prod_{i=1}^{j-1}\mathbf{u}_t[\phi_t[i]]$                                                                                                                                                                                   | Allocation weighting                       |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| C_(t)^(w) = 𝒞(M_(t − 1), K_(t)^(w), β_(t)^(w))                                                                                                                                                                                                                                  | Write content weighting                    |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| C_(t)^(r, i) = 𝒞(M_(t − 1), K_(t)^(r, i), β_(t)^(r, i))                                                                                                                                                                                                                         | Read content weighting                     |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| F_(t)^(i) = L_(t)W_(t − 1)^(r, i)                                                                                                                                                                                                                                               | Forward weighting                          |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| B_(t)^(i) = L_(t)^(⊺)W_(t − 1)^(r, i)                                                                                                                                                                                                                                           | Backward weighting                         |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| $\boldsymbol\psi_t=\prod_{i=1}^R\left(\mathbf{1}-f_t^i\mathbf{w}_{t-1}^{r,i}\right)$                                                                                                                                                                                            | Memory retention vector                    |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| DEFINITIONS                                                                                                                                                                                                                                                                     |                                            |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| W, B                                                                                                                                                                                                                                                                            | Weight matrix, bias vector                 |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| 0, 1, I                                                                                                                                                                                                                                                                         | Zeros matrix, ones matrix, identity matrix |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| ∘                                                                                                                                                                                                                                                                               | Element-wise multiplication                |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| $\mathcal{D}(\mathbf{u},\mathbf{v})=\frac{\mathbf{u}\cdot\mathbf{v}}{\|\mathbf{u}\|\|\mathbf{v}\|}$                                                                                                                                                                             | Cosine similarity                          |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| σ(x) = 1/(1 + e^( − x))                                                                                                                                                                                                                                                         | Sigmoid function                           |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| oneplus(x) = 1 + log (1 + e^(x))                                                                                                                                                                                                                                                | Oneplus function                           |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| $\text{softmax}(\mathbf{x})_j = \frac{e^{x_j}}{\sum_{k=1}^K e^{x_k}}$    for _j_ = 1, …, _K_.                                                                                                                                                                                   | Softmax function                           |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+

Extensions

Refinements to the model have been published since the original paper's release. Sparse memory addressing results in a time and space complexity reduction of thousands of times. This can be achieved by using an approximate nearest neighbors algorithm, such as Locality-sensitive hashing, or a random k-d tree like the Fast Library for Approximate Nearest Neighbors from UBC.[14] Adding Adaptive Computation Time (ACT) separates computation time from data time, which uses the fact that problem length and problem difficulty are not always the same.[15] Training using synthetic gradients performs considerably better than Backpropagation through time (BPTT).[16] Another training improvement in terms of robustness can be achieved with use of DNA normalization and a Bypass Dropout as regularization.[17]


References


External links

-   A bit-by-bit guide to the equations governing differentiable neural computers

Category:Artificial neural networks Category:Artificial intelligence

[1]

[2]

[3]  DeepMind|website=DeepMind|access-date=2016-10-19}}

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]

[17]